import collections
import datetime
import logging
import os

from paste.deploy.converters import asbool

from ckan import model
from ckan.common import OrderedDict

import ckan.plugins as p

from ckanext.report import lib
from helpers import go_up_tree, group_get_users, organization_list

log = logging.getLogger(__name__)

# NII

def nii_report():
    '''A list of the NII datasets, grouped by publisher, with details of broken
    links and source.'''
    nii_dataset_q = model.Session.query(model.Package)\
        .join(model.PackageExtra, model.PackageExtra.package_id == model.Package.id)\
        .join(model.Group, model.Package.owner_org == model.Group.id)\
        .filter(model.PackageExtra.key == 'core-dataset')\
        .filter(model.PackageExtra.value == 'true')\
        .filter(model.Package.state == 'active')
    nii_dataset_objects = nii_dataset_q\
            .order_by(model.Group.title, model.Package.title).all()

    def broken_resources_for_package(package_id):
        from ckanext.archiver.model import Archival

        results = model.Session.query(Archival, model.Resource)\
                       .filter(Archival.package_id == package_id)\
                       .filter(Archival.is_broken == True)\
                       .join(model.Package, Archival.package_id == model.Package.id)\
                       .filter(model.Package.state == 'active')\
                       .join(model.Resource, Archival.resource_id == model.Resource.id)\
                       .filter(model.Resource.state == 'active')

        broken_resources = [(resource.description, resource.id)
                            for archival, resource in results.all()]
        return broken_resources

    nii_dataset_details = []
    num_resources = 0
    num_broken_resources = 0
    num_broken_datasets = 0
    broken_organization_names = set()
    nii_organizations = set()
    for dataset_object in nii_dataset_objects:
        broken_resources = broken_resources_for_package(dataset_object.id)
        org = dataset_object.get_organization()
        dataset_details = {
                'name': dataset_object.name,
                'title': dataset_object.title,
                'dataset_notes': lib.dataset_notes(dataset_object),
                'organization_name': org.name,
                'unpublished': p.toolkit.asbool(dataset_object.extras.get('unpublished')),
                'num_broken_resources': len(broken_resources),
                'broken_resources': broken_resources,
                }
        nii_dataset_details.append(dataset_details)
        if broken_resources:
            num_broken_resources += len(broken_resources)
            num_broken_datasets += 1
            broken_organization_names.add(org.name)
        nii_organizations.add(org)
        num_resources += len(dataset_object.resources)

    org_tuples = [(org.name, org.title) for org in
                  sorted(nii_organizations, key=lambda o: o.title)]

    return {'table': nii_dataset_details,
            'organizations': org_tuples,
            'num_resources': num_resources,
            'num_datasets': len(nii_dataset_objects),
            'num_organizations': len(nii_organizations),
            'num_broken_resources': num_broken_resources,
            'num_broken_datasets': num_broken_datasets,
            'num_broken_organizations': len(broken_organization_names),
            }

nii_report_info = {
    'name': 'nii',
    'title': 'National Information Infrastructure',
    'description': 'Details of the datasets in the NII.',
    'option_defaults': OrderedDict([]),
    'option_combinations': None,
    'generate': nii_report,
    'template': 'report/nii.html',
}


# Publisher resources


def publisher_resources(organization=None,
                        include_sub_organizations=False):
    '''
    Returns a dictionary detailing resources for each dataset in the
    organisation specified.
    '''
    org = model.Group.by_name(organization)
    if not org:
        raise p.toolkit.ObjectNotFound('Publisher not found')

    # Get packages
    pkgs = model.Session.query(model.Package)\
                .filter_by(state='active')
    pkgs = lib.filter_by_organizations(pkgs, organization,
                                       include_sub_organizations).all()

    # Get their resources
    def create_row(pkg_, resource_dict):
        org_ = pkg_.get_organization()
        return OrderedDict((
                ('publisher_title', org_.title),
                ('publisher_name', org_.name),
                ('package_title', pkg_.title),
                ('package_name', pkg_.name),
                ('package_notes', lib.dataset_notes(pkg_)),
                ('resource_position', resource_dict.get('position')),
                ('resource_id', resource_dict.get('id')),
                ('resource_description', resource_dict.get('description')),
                ('resource_url', resource_dict.get('url')),
                ('resource_format', resource_dict.get('format')),
                ('resource_created', resource_dict.get('created')),
               ))
    num_resources = 0
    rows = []
    for pkg in pkgs:
        resources = pkg.resources
        if resources:
            for res in resources:
                res_dict = {'id': res.id, 'position': res.position,
                            'description': res.description, 'url': res.url,
                            'format': res.format,
                            'created': (res.created.isoformat()
                                        if res.created else None)}
                rows.append(create_row(pkg, res_dict))
            num_resources += len(resources)
        else:
            # packages with no resources are still listed
            rows.append(create_row(pkg, {}))

    return {'organization_name': org.name,
            'organization_title': org.title,
            'num_datasets': len(pkgs),
            'num_resources': num_resources,
            'table': rows,
            }

def publisher_resources_combinations():
    for organization in lib.all_organizations():
        for include_sub_organizations in (False, True):
                yield {'organization': organization,
                       'include_sub_organizations': include_sub_organizations}

publisher_resources_info = {
    'name': 'publisher-resources',
    'description': 'A list of all the datasets and resources for a publisher.',
    'option_defaults': OrderedDict((('organization', 'cabinet-office'),
                                    ('include_sub_organizations', False))),
    'option_combinations': publisher_resources_combinations,
    'generate': publisher_resources,
    'template': 'report/publisher_resources.html',
    }


def get_quarter_dates(datetime_now):
    '''Returns the dates for this (current) quarter and last quarter. Uses
    calendar year, so 1 Jan to 31 Mar etc.'''
    now = datetime_now
    month_this_q_started = (now.month - 1) // 3 * 3 + 1
    this_q_started = datetime.datetime(now.year, month_this_q_started, 1)
    this_q_ended = datetime.datetime(now.year, now.month, now.day)
    last_q_started = datetime.datetime(
                      this_q_started.year + (this_q_started.month-3)/12,
                      (this_q_started.month-4) % 12 + 1,
                      1)
    last_q_ended = this_q_started - datetime.timedelta(days=1)
    return {'this': (this_q_started, this_q_ended),
            'last': (last_q_started, last_q_ended)}


def get_quarter_dates_merged(datetime_now):
    '''Returns the dates for the period including this (current) quarter and
    the last quarter. Uses calendar year, so 1 Jan to 31 Mar etc.'''
    now = datetime_now
    month_this_q_started = (now.month - 1) // 3 * 3 + 1
    this_q_started = datetime.datetime(now.year, month_this_q_started, 1)
    this_q_ended = datetime.datetime(now.year, now.month, now.day)
    last_q_started = datetime.datetime(
                      this_q_started.year + (this_q_started.month-3)/12,
                      (this_q_started.month-4) % 12 + 1,
                      1)
    last_q_ended = this_q_started - datetime.timedelta(days=1)
    return {'this_and_last': (last_q_started, this_q_ended)}


def publisher_activity(organization, include_sub_organizations=False):
    """
    Contains information about the datasets a specific organization has
    released in this and last quarter (calendar year). This is needed by
    departments for their quarterly transparency reports.
    """
    import datetime

    now = datetime.datetime.now()

    if organization:
        quarters = get_quarter_dates(now)

        created, modified = _get_activity(
            organization, include_sub_organizations, quarters)

        datasets = []
        for quarter_name in quarters:
            datasets += sorted(created[quarter_name], key=lambda x: x[1])
            datasets += sorted(modified[quarter_name], key=lambda x: x[1])
        columns = ('Dataset name', 'Dataset title', 'Dataset notes', 'Modified or created', 'Quarter', 'Timestamp', 'Author', 'Published')

        quarters_iso = dict(
            [(last_or_this, [date_.isoformat() for date_ in q_list])
             for last_or_this, q_list in quarters.iteritems()])

        return {'table': datasets, 'columns': columns,
                'quarters': quarters_iso}
    else:
        # index
        periods = get_quarter_dates_merged(now)

        stats_by_org = []
        totals = collections.defaultdict(int)
        import ckan.model as model
        all_orgs = model.Session.query(model.Group).\
            filter(model.Group.type=='organization').\
            filter(model.Group.state=='active').order_by('name').\
            all()
        for organization in add_progress_bar(all_orgs):
            created, modified = _get_activity(
                organization.name, include_sub_organizations, periods)
            created_names = [dataset[0] for dataset in created.values()[0]]
            modified_names = [dataset[0] for dataset in modified.values()[0]]
            num_created = len(created_names)
            num_modified = len(modified_names)
            num_total = len(set(created_names) | set(modified_names))
            stats_by_org.append(OrderedDict((
                ('organization name', organization.name),
                ('organization title', organization.title),
                ('num created', num_created),
                ('num modified', num_modified),
                ('total', num_total),
                )))
            if not include_sub_organizations:
                totals['num created'] += num_created
                totals['num modified'] += num_modified
                totals['total'] += num_total

        period_iso = [date_.isoformat()
                      for date_ in periods.values()[0]]

        stats_by_org.sort(key=lambda x: -x['total'])

        return {'table': stats_by_org,
                'totals': totals,
                'period': period_iso}


def _get_activity(organization_name, include_sub_organizations, periods):
    import ckan.model as model
    from paste.deploy.converters import asbool

    created = dict((period_name, []) for period_name in periods)
    modified = dict((period_name, []) for period_name in periods)

    # These are the authors whose revisions we ignore, as they are trivial
    # changes. NB we do want to know about revisions by:
    # * harvest (harvested metadata)
    # * dgu (NS Stat Hub imports)
    # * Fix national indicators
    system_authors = ('autotheme', 'co-prod3.dh.bytemark.co.uk',
                      'Date format tidier', 'current_revision_fixer',
                      'current_revision_fixer2', 'fix_contact_details.py',
                      'Repoint 410 Gone to webarchive url',
                      'Fix duplicate resources',
                      'fix_secondary_theme.py',
                      )
    system_author_template = 'script%'  # "%" is a wildcard

    if organization_name:
        organization = model.Group.by_name(organization_name)
        if not organization:
            raise p.toolkit.ObjectNotFound()

    if not organization_name:
        pkgs = model.Session.query(model.Package)\
                    .all()
    else:
        pkgs = model.Session.query(model.Package)
        pkgs = lib.filter_by_organizations(pkgs, organization,
                                           include_sub_organizations).all()

    for pkg in pkgs:
        created_ = model.Session.query(model.PackageRevision)\
            .filter(model.PackageRevision.id == pkg.id) \
            .order_by("revision_timestamp asc").first()

        pr_q = model.Session.query(model.PackageRevision, model.Revision)\
            .filter(model.PackageRevision.id == pkg.id)\
            .filter_by(state='active')\
            .join(model.Revision)\
            .filter(~model.Revision.author.in_(system_authors)) \
            .filter(~model.Revision.author.like(system_author_template))

#            .join(model.ResourceGroup)\
#            .join(model.ResourceRevision,
#                  model.ResourceGroup.id == model.ResourceRevision.resource_group_id)\

        rr_q = model.Session.query(model.Package, model.ResourceRevision, model.Revision)\
            .filter(model.Package.id == pkg.id)\
            .filter_by(state='active')\
            .join(model.Revision)\
            .filter(~model.Revision.author.in_(system_authors))\
            .filter(~model.Revision.author.like(system_author_template))
        pe_q = model.Session.query(model.Package, model.PackageExtraRevision, model.Revision)\
            .filter(model.Package.id == pkg.id)\
            .filter_by(state='active')\
            .join(model.PackageExtraRevision,
                  model.Package.id == model.PackageExtraRevision.package_id)\
            .join(model.Revision)\
            .filter(~model.Revision.author.in_(system_authors))\
            .filter(~model.Revision.author.like(system_author_template))

        for period_name in periods:
            period = periods[period_name]
            # created
            if period[0] < created_.revision_timestamp < period[1]:
                published = not asbool(pkg.extras.get('unpublished'))
                created[period_name].append(
                    (created_.name, created_.title, lib.dataset_notes(pkg),
                     'created', period_name,
                     created_.revision_timestamp.isoformat(),
                     created_.revision.author, published))

            # modified
            # exclude the creation revision
            period_start = max(period[0], created_.revision_timestamp)
            prs = pr_q.filter(model.PackageRevision.revision_timestamp > period_start)\
                        .filter(model.PackageRevision.revision_timestamp < period[1])
            rrs = rr_q.filter(model.ResourceRevision.revision_timestamp > period_start)\
                        .filter(model.ResourceRevision.revision_timestamp < period[1])
            pes = pe_q.filter(model.PackageExtraRevision.revision_timestamp > period_start)\
                        .filter(model.PackageExtraRevision.revision_timestamp < period[1])
            authors = ' '.join(set([r[1].author for r in prs] +
                                   [r[2].author for r in rrs] +
                                   [r[2].author for r in pes]))
            dates = set([r[1].timestamp.date() for r in prs] +
                        [r[2].timestamp.date() for r in rrs] +
                        [r[2].timestamp.date() for r in pes])
            dates_formatted = ' '.join([date.isoformat()
                                        for date in sorted(dates)])
            if authors:
                published = not asbool(pkg.extras.get('unpublished'))
                modified[period_name].append(
                    (pkg.name, pkg.title, lib.dataset_notes(pkg),
                        'modified', period_name,
                        dates_formatted, authors, published))
    return created, modified


def publisher_activity_combinations():
    for org in lib.all_organizations(include_none=True):
        for include_sub_organizations in (False, True):
            yield {'organization': org,
                   'include_sub_organizations': include_sub_organizations}

publisher_activity_report_info = {
    'name': 'publisher-activity',
    'description': 'A quarterly list of datasets created and edited by a publisher.',
    'option_defaults': OrderedDict((('organization', None),
                                    ('include_sub_organizations', False),
                                    )),
    'option_combinations': publisher_activity_combinations,
    'generate': publisher_activity,
    'template': 'report/publisher_activity.html',
    }


def unpublished():
    pkgs = model.Session.query(model.Package)\
                .filter_by(state='active')\
                .join(model.PackageExtra)\
                .filter_by(key='unpublished')\
                .filter_by(value='true')\
                .filter_by(state='active')\
                .all()
    pkg_dicts = []
    for pkg in pkgs:
        org = pkg.get_organization()
        pkg_dict = {
                'name': pkg.name,
                'title': pkg.title,
                'organization title': org.title,
                'organization name': org.name,
                'notes': pkg.notes,
                'publish date': pkg.extras.get('publish-date'),
                'will not be released': pkg.extras.get('publish-restricted'),
                'release notes': pkg.extras.get('release-notes'),
                }
        pkg_dicts.append(pkg_dict)
    return {'table': pkg_dicts}

unpublished_report_info = {
    'name': 'unpublished',
    'title': 'Unpublished datasets',
    'description': 'Unpublished dataset properties provided by publishers.',
    'option_defaults': None,
    'option_combinations': None,
    'generate': unpublished,
    'template': 'report/unpublished.html',
    }

def last_resource_deleted(pkg):

    #    .join(model.ResourceGroup) \
    resource_revisions = model.Session.query(model.ResourceRevision) \
        .join(model.Package) \
        .filter_by(id=pkg.id) \
        .order_by(model.ResourceRevision.revision_timestamp) \
        .all()
    previous_rr = None
    # go through the RRs in reverse chronological order and when an active
    # revision is found, return the rr in the previous loop.
    for rr in resource_revisions[::-1]:
        if rr.state == 'active':
            if not previous_rr:
                # this happens v.v. occasionally where a resource_revision and
                # its resource somehow manages to have a different
                # resource_group_id
                return None, ''
            return previous_rr.revision_timestamp, previous_rr.url
        previous_rr = rr
    return None, ''

def datasets_without_resources(organization=None, include_sub_organizations=False):
    pkg_dicts = []
    pkgs = model.Session.query(model.Package)\
                .filter_by(state='active')\
                .order_by(model.Package.title)\
                .all()
    if organization:
        pkgs = lib.filter_by_organizations(pkgs, organization,
                                        include_sub_organizations)

    for pkg in add_progress_bar(pkgs):
        if len(pkg.resources) != 0 or \
                pkg.extras.get('unpublished', '').lower() == 'true':
            continue
        deleted, url = last_resource_deleted(pkg)
        pkg_dict = OrderedDict((
            ('name', pkg.name),
            ('title', pkg.title),
            ('metadata created', pkg.metadata_created.isoformat()),
            ('metadata modified', pkg.metadata_modified.isoformat()),
            ('last resource deleted', deleted.isoformat() if deleted else None),
            ('last resource url', url),
            ('dataset_notes', lib.dataset_notes(pkg)),
            ))
        pkg_dicts.append(pkg_dict)
    return {'table': pkg_dicts}


def dataset_without_resources_report_option_combinations():
    for organization in lib.all_organizations(include_none=True):
        for include_sub_organizations in (False, True):
            yield {'organization': organization,
                   'include_sub_organizations': include_sub_organizations}

datasets_without_resources_info = {
    'name': 'datasets-without-resources',
    'title': 'Datasets without resources',
    'description': 'Datasets that have no resources (data URLs). Excludes unpublished ones.',
    'option_defaults': None,
    'option_defaults': OrderedDict((('organization', None),
                                    ('include_sub_organizations', False),
                                    )),
    'option_combinations': dataset_without_resources_report_option_combinations,
    'generate': datasets_without_resources,
    'template': 'report/datasets_without_resources.html',
    }


# app-dataset

def app_dataset_report():
    app_dataset_dicts = []
    for related in model.Session.query(model.RelatedDataset) \
                        .filter(model.Related.type=='App') \
                        .all():
        dataset = related.dataset
        org = dataset.get_organization()
        top_org = list(go_up_tree(org))[-1]

        app_dataset_dict = OrderedDict((
            ('app title', related.related.title),
            ('app url', related.related.url),
            ('dataset name', dataset.name),
            ('dataset title', dataset.title),
            ('organization title', org.title),
            ('organization name', org.name),
            ('top-level organization title', top_org.title),
            ('top-level organization name', top_org.name),
            ('dataset theme', related.dataset.extras.get('theme-primary', '')),
            ('dataset notes', lib.dataset_notes(dataset)),
            ))
        app_dataset_dicts.append(app_dataset_dict)

    app_dataset_dicts.sort(key=lambda row: row['top-level organization title']
                           + row['organization title'])

    return {'table': app_dataset_dicts}

app_dataset_report_info = {
    'name': 'app-dataset-report',
    'title': 'Apps with datasets',
    'description': 'Datasets that have been used by apps.',
    'option_defaults': None,
    'option_combinations': None,
    'generate': app_dataset_report,
    'template': 'report/app_dataset.html',
    }

# app-dataset by theme

def app_dataset_theme_report():
    table = []

    datasets = collections.defaultdict(lambda: {'apps': []})
    for related in model.Session.query(model.RelatedDataset).filter(model.Related.type=='App').all():
        dataset_name = related.dataset.name

        app = {
          'title': related.related.title,
          'url': related.related.url
        }

        datasets[dataset_name]['title'] = related.dataset.title
        datasets[dataset_name]['theme'] = related.dataset.extras.get('theme-primary', '')
        datasets[dataset_name]['apps'].append(app)

    for dataset_name, dataset in datasets.items():
        sorted_apps = sorted(dataset['apps'], key=lambda x: x['title'])
        table.append({'dataset_title': dataset['title'],
                      'dataset_name': dataset_name,
                      'theme': dataset['theme'],
                      'app_titles': "\n".join(a['title'] for a in sorted_apps),
                      'app_urls': "\n".join(a['url'] for a in sorted_apps)})

    return {'table': table}

app_dataset_theme_report_info = {
    'name': 'app-dataset-theme-report',
    'title': 'Apps with datasets by theme',
    'description': 'Datasets that have been used by apps, grouped by theme.',
    'option_defaults': None,
    'option_combinations': None,
    'generate': app_dataset_theme_report,
    'template': 'report/app_dataset_theme_report.html',
    }

# admin-editor report

def admin_editor(org=None, include_sub_organizations=False):

    table = []

    if org:
        q = model.Group.all('organization')
        parent = model.Group.by_name(org)
        if not parent:
            raise p.toolkit.ObjectNotFound('Publisher not found')

        if include_sub_organizations:
            child_ids = [ch[0] for ch in parent.get_children_group_hierarchy(type='organization')]
        else:
            child_ids = []

        q = q.filter(model.Group.id.in_([parent.id] + child_ids))

        for g in q.all():
            record = {}
            record['publisher_name'] = g.name
            record['publisher_title'] = g.title

            admin_users = group_get_users(g, capacity='admin')
            admins = []
            for u in admin_users:
                admins.append('%s <%s>' % (u.name, u.email))

            record['admins'] = "\n".join(admins)

            editor_users = group_get_users(g, capacity='editor')
            editors = []
            for u in editor_users:
                editors.append('%s <%s>' % (u.name, u.email))

            record['editors'] = "\n".join(editors)
            table.append(record)
    else:
        table.append({})

    return {'table': table}

def admin_editor_combinations():

    for org, _ in organization_list(top=False):
        for include_sub_organizations in (False, True):
            yield {'org': org,
                    'include_sub_organizations': include_sub_organizations}

def user_is_admin(user, org=None):
    import ckan.lib.helpers as helpers
    if org:
        return helpers.check_access('organization_update', {'id': org.id})
    else:
        # Are they admin of any org?
        return len(user.get_groups('organization', capacity='admin')) > 0

def admin_editor_authorize(user, options):
    if not user:
        return False

    if user.sysadmin:
        return True

    if options.get('org', False):
        org_name = options["org"]
        org = model.Session.query(model.Group) \
                   .filter_by(name=org_name) \
                   .first()
        if not org:
            return False

        if user_is_admin(user, org):
            return True
        else:
            return False
    else:
        # Allow them to see front page / see report on report index
        if user_is_admin(user):
            return True

    return False

admin_editor_info = {
    'name': 'admin_editor',
    'title': 'Publisher administrators and editors',
    'description': 'Filterable list of publishers which shows who has administrator and editor rights.',
    'option_defaults': OrderedDict((('org', ''), ('include_sub_organizations', False))),
    'option_combinations': admin_editor_combinations,
    'generate': admin_editor,
    'template': 'report/admin_editor.html',
    'authorize': admin_editor_authorize
    }


# Licence report

def licence_report(organization=None, include_sub_organizations=False):
    '''
    Returns a dictionary detailing licences for datasets in the
    organisation specified, and optionally sub organizations.
    '''
    # Get packages
    if organization:
        top_org = model.Group.by_name(organization)
        if not top_org:
            raise p.toolkit.ObjectNotFound('Publisher not found')

        if include_sub_organizations:
            orgs = lib.go_down_tree(top_org)
        else:
            orgs = [top_org]
        pkgs = set()
        for org in orgs:
            org_pkgs = model.Session.query(model.Package)\
                            .filter_by(state='active')
            org_pkgs = lib.filter_by_organizations(
                org_pkgs, organization,
                include_sub_organizations=False)\
                .all()
            pkgs |= set(org_pkgs)
    else:
        pkgs = model.Session.query(model.Package)\
                    .filter_by(state='active')\
                    .all()

    # Get their licences
    packages_by_licence = collections.defaultdict(list)
    rows = []
    num_pkgs = 0
    for pkg in pkgs:
        if asbool(pkg.extras.get('unpublished')) is True:
            # Ignore unpublished datasets
            continue
        licence_tuple = (pkg.license_id or '',
                         pkg.license.title if pkg.license else '',
                         pkg.extras.get('licence', ''))
        packages_by_licence[licence_tuple].append((pkg.name, pkg.title))
        num_pkgs += 1

    for licence_tuple, dataset_tuples in sorted(packages_by_licence.items(),
                                                key=lambda x: -len(x[1])):
        license_id, license_title, licence = licence_tuple
        dataset_tuples.sort(key=lambda x: x[0])
        dataset_names, dataset_titles = zip(*dataset_tuples)
        licence_dict = OrderedDict((
            ('license_id', license_id),
            ('license_title', license_title),
            ('licence', licence),
            ('dataset_titles', '|'.join(t for t in dataset_titles)),
            ('dataset_names', ' '.join(dataset_names)),
            ))
        rows.append(licence_dict)

    return {
        'num_datasets': num_pkgs,
        'num_licences': len(rows),
        'table': rows,
        }


def licence_combinations():
    for organization in lib.all_organizations(include_none=True):
        for include_sub_organizations in (False, True):
                yield {'organization': organization,
                       'include_sub_organizations': include_sub_organizations}


licence_report_info = {
    'name': 'licence',
    'title': 'Licences',
    'description': 'Licenses for datasets.',
    'option_defaults': OrderedDict((('organization', None),
                                    ('include_sub_organizations', False))),
    'option_combinations': licence_combinations,
    'generate': licence_report,
    'template': 'report/licence_report.html',
    }


# Datasets only in PDF

def pdf_datasets_report():
    '''
    Returns datasets that have data in PDF format, by organization.
    '''
    # Get packages
    pkgs = model.Session.query(model.Package)\
                .filter_by(state='active')

    # See if PDF
    num_datasets_published = 0
    num_datasets_only_pdf = 0
    packages = []
    # use yield_per, otherwise memory use just goes up til the script is killed
    # by the os.
    for pkg in pkgs.yield_per(100):
        if p.toolkit.asbool(pkg.extras.get('unpublished')):
            continue
        num_datasets_published += 1

        formats = set([res.format.lower() for res in pkg.resources
                       if res.resource_type != 'documentation'])
        if 'pdf' not in formats:
            continue

        data_formats = formats - set(('html', '', None))
        if data_formats == set(('pdf',)):
            num_datasets_only_pdf += 1
            packages.append(pkg)

    rows = []
    for pkg in packages:
	print pkg.name
        pkg_dict = OrderedDict((
            ('name', pkg.name),
            ('title', pkg.title),
            ('metadata created', pkg.metadata_created.isoformat()),
            ('metadata modified', pkg.metadata_modified.isoformat()),
            ('dataset_notes', lib.dataset_notes(pkg)),
            ))
        rows.append(pkg_dict)

    return {'table': rows,
            'num_datasets_published': num_datasets_published,
            'num_datasets_only_pdf': num_datasets_only_pdf,
            }

    for pkg in add_progress_bar(pkgs):
        if len(pkg.resources) != 0 or \
                pkg.extras.get('unpublished', '').lower() == 'true':
            continue
        deleted, url = last_resource_deleted(pkg)
    return {'table': pkg_dicts}



pdf_datasets_report_info = {
    'name': 'pdf_datasets',
    'title': 'PDF Datasets',
    'description': 'Datasets with data only in PDF format.',
    'option_defaults': None,
    'option_combinations': None,
    'generate': pdf_datasets_report,
    'template': 'report/pdf_datasets_report.html',
    }


# Datasets with HTML link

def html_datasets_report():
    '''
    Returns datasets that only have an HTML link, by organization.
    '''
    # Get packages
    pkgs = model.Session.query(model.Package)\
                .filter_by(state='active')

    # See if HTML
    num_datasets_published = 0
    num_datasets_only_html = 0
    datasets_by_publisher_only_html = collections.defaultdict(list)
    # use yield_per, otherwise memory use just goes up til the script is killed
    # by the os.
    for pkg in pkgs.yield_per(100):
        if p.toolkit.asbool(pkg.extras.get('unpublished')):
            continue
        num_datasets_published += 1

        formats = set([res.format.lower() for res in pkg.resources
                       if res.resource_type != 'documentation'])
        if 'html' not in formats:
            continue
        org = pkg.get_organization().name

        data_formats = formats - set(('asp', '', None))
        if data_formats == set(('html',)):
            num_datasets_only_html += 1
            datasets_by_publisher_only_html[org].append((pkg.name, pkg.title))

    rows = []
    for org_name, datasets_only_html in sorted(
            datasets_by_publisher_only_html.iteritems(),
            key=lambda x: -len(x[1])):
        org = model.Session.query(model.Group) \
                   .filter_by(name=org_name) \
                   .first()
        top_org = list(go_up_tree(org))[-1]

        row = OrderedDict((
            ('organization title', org.title),
            ('organization name', org.name),
            ('top-level organization title', top_org.title),
            ('top-level organization name', top_org.name),
            ('num datasets only html', len(datasets_only_html)),
            ('name datasets only html',
             ' '.join(d[0] for d in datasets_only_html)),
            ('title datasets only html',
             '|'.join(d[1] for d in datasets_only_html)),
            ))
        rows.append(row)

    return {'table': rows,
            'num_datasets_published': num_datasets_published,
            'num_datasets_only_html': num_datasets_only_html,
            }


html_datasets_report_info = {
    'name': 'html_datasets',
    'title': 'HTML Datasets',
    'description': 'Datasets with data only a link to an HTML page.',
    'option_defaults': None,
    'option_combinations': None,
    'generate': html_datasets_report,
    'template': 'report/html_datasets_report.html',
    }


def add_progress_bar(iterable, caption=None):
    try:
        # Add a progress bar, if it is installed
        import progressbar
        bar = progressbar.ProgressBar(widgets=[
            (caption + ' ') if caption else '',
            progressbar.Percentage(), ' ',
            progressbar.Bar(), ' ', progressbar.ETA()])
        return bar(iterable)
    except ImportError:
        return iterable


